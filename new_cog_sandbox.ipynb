{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package benepar_en3 to /Users/szczekulskij/.py\n",
      "[nltk_data]     env/versions/3.10.15/envs/cognify/share/nltk_data...\n",
      "[nltk_data]   Package benepar_en3 is already up-to-date!\n",
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['a clock above a building with clouds and lightning background', 'a clock', 'a building with clouds and lightning background', 'a building', 'clouds and lightning background', 'clouds', 'lightning background']\n",
      "['this weather phenomenon']\n",
      "['what unpleasant emotion does a clock above a building with clouds and lightning background evoke?', 'what unpleasant emotion does a clock evoke?', 'what unpleasant emotion does a building with clouds and lightning background evoke?', 'what unpleasant emotion does a building evoke?', 'what unpleasant emotion does clouds and lightning background evoke?', 'what unpleasant emotion does clouds evoke?', 'what unpleasant emotion does lightning background evoke?']\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain.output_parsers import PydanticOutputParser\n",
    "from pydantic import BaseModel, validator\n",
    "import dotenv\n",
    "import os\n",
    "from typing import List\n",
    "\n",
    "\n",
    "from constituent_treelib import ConstituentTree, Language\n",
    "# Define the language for the sentence as well as for the spaCy and benepar models\n",
    "language = Language.English\n",
    "# Define which specific SpaCy model should be used (default is Medium)\n",
    "spacy_model_size = ConstituentTree.SpacyModelSize.Medium\n",
    "# Create the pipeline (note, the required models will be downloaded and installed automatically)\n",
    "nlp = ConstituentTree.create_pipeline(language, spacy_model_size)\n",
    "# Your sentence\n",
    "\n",
    "\n",
    "def get_constituents(sentence: str) -> list[str]:\n",
    "    # Create the tree from where we are going to extract the desired noun phrases\n",
    "    tree = ConstituentTree(sentence, nlp)\n",
    "    all_phrases = tree.extract_all_phrases(min_words_in_phrases=1)\n",
    "    return all_phrases[\"NP\"]\n",
    "\n",
    "\n",
    "\n",
    "caption = \"a clock above a building with clouds and lightning background\"\n",
    "question = \"what unpleasant emotion does this weather phenomenon evoke?\"\n",
    "\n",
    "caption_constituents = get_constituents(caption)\n",
    "print(caption_constituents)\n",
    "\n",
    "question_constituents = get_constituents(question)\n",
    "print(question_constituents)\n",
    "\n",
    "\n",
    "def get_all_possible_question_rewrites(question : str, \n",
    "                                       caption_constituents : list[str], \n",
    "                                       question_constituents : list[str]) -> list[str]:\n",
    "    questions = []\n",
    "    for q in question_constituents:\n",
    "        for c in caption_constituents:\n",
    "            new_sentence = question.replace(q, c)\n",
    "            questions.append(new_sentence)\n",
    "\n",
    "    # return all possible re-written questions\n",
    "    return questions\n",
    "\n",
    "\n",
    "questions = get_all_possible_question_rewrites(question, caption_constituents, question_constituents)\n",
    "print(questions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/n2/5fn7vvhn3gb8s8nvtd_42ttc0000gn/T/ipykernel_50914/2964411331.py:7: PydanticDeprecatedSince20: Pydantic V1 style `@validator` validators are deprecated. You should migrate to Pydantic V2 style `@field_validator` validators, see the migration guide for more details. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.10/migration/\n",
      "  @validator('score')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM chose index 4 with score 6 because: The clouds and lightning are related to weather, but the question lacks specificity about the phenomenon, reducing its relevance.\n",
      "The best question is: what unpleasant emotion does clouds and lightning background evoke?\n"
     ]
    }
   ],
   "source": [
    "dotenv.load_dotenv()\n",
    "\n",
    "class RelevanceAssessment(BaseModel):\n",
    "    score: int\n",
    "    reason: str\n",
    "\n",
    "    @validator('score')\n",
    "    def score_must_be_in_range(cls, value):\n",
    "        if not 1 <= value <= 10:\n",
    "            raise ValueError('Score must be between 1 and 10')\n",
    "        return value\n",
    "\n",
    "class BatchRelevanceAssessment(BaseModel):\n",
    "    assessments: List[RelevanceAssessment]\n",
    "\n",
    "parser = PydanticOutputParser(pydantic_object=BatchRelevanceAssessment)\n",
    "\n",
    "\n",
    "def assess_relevance_batch(original_question: str, new_questions: List[str], model: ChatOpenAI) -> List[RelevanceAssessment]:\n",
    "    \"\"\"Assesses the relevance of a batch of new questions compared to the original.\"\"\"\n",
    "\n",
    "    prompt = ChatPromptTemplate.from_messages(\n",
    "        [\n",
    "            (\"system\", \"\"\"You are an expert in language and reasoning. \n",
    "             Your task is to assess how well each new question retains the meaning and intent of the original question,\n",
    "             considering a substitution that has been made.\n",
    "             For each new question, compare the original question to the new question. Think step by step about whether the substitution makes sense\n",
    "             in the context of the question and whether it preserves the original intent.\n",
    "             Provide a score from 1 to 10 for each new question, where 1 means the new question is completely irrelevant to the original,\n",
    "             and 10 means the new question is perfectly relevant and retains the original intent.\n",
    "             Explain your reasoning for each question in a short sentence.\n",
    "\n",
    "             Return a JSON array of objects, where each object has a \"score\" and a \"reason\" field.\n",
    "             The scores must be between 1 and 10 (inclusive).\n",
    "             Your response format should be: {format_instructions}\n",
    "             \"\"\"),\n",
    "            (\"human\", \"Original question: {original_question}\\nNew questions:\\n{new_questions}\")\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    chain = prompt | model | parser\n",
    "\n",
    "    # Format the new questions for the prompt\n",
    "    formatted_questions = \"\\n\".join([f\"{i+1}. {q}\" for i, q in enumerate(new_questions)])\n",
    "\n",
    "    input = {\"original_question\": original_question,\n",
    "             \"new_questions\": formatted_questions,\n",
    "             \"format_instructions\": parser.get_format_instructions()}\n",
    "\n",
    "    output = chain.invoke(input)\n",
    "    return output.assessments\n",
    "\n",
    "\n",
    "def choose_the_best_questions(original_question: str, all_possible_sentences: List[str]) -> str:\n",
    "    ''' Given all possible sentences, choose the one that is most relevant to the original question\n",
    "      after considering the substitutions made.'''\n",
    "\n",
    "    model = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
    "\n",
    "    sentence_assessments = assess_relevance_batch(original_question, all_possible_sentences, model)\n",
    "\n",
    "    # Find the sentence with the highest relevance score\n",
    "    best_sentence = None\n",
    "    best_score = -1\n",
    "    best_index = -1\n",
    "\n",
    "    for i, assessment in enumerate(sentence_assessments):\n",
    "        if assessment.score > best_score:\n",
    "            best_score = assessment.score\n",
    "            best_sentence = all_possible_sentences[i]\n",
    "            best_index = i\n",
    "\n",
    "    print(f\"LLM chose index {best_index} with score {best_score} because: {sentence_assessments[best_index].reason}\")\n",
    "\n",
    "    if best_sentence is None:\n",
    "        print(\"No sentences were assessed. Returning the first question.\")\n",
    "        return all_possible_sentences[0]\n",
    "\n",
    "    return best_sentence\n",
    "\n",
    "best_question = choose_the_best_questions(question, questions)\n",
    "print(f\"The best question is: {best_question}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reWriteQuery(caption: str, question: str) -> str:\n",
    "    caption_constituents = get_constituents(caption)\n",
    "    question_constituents = get_constituents(question)\n",
    "    questions = get_all_possible_question_rewrites(question, caption_constituents, question_constituents)\n",
    "    best_question = choose_the_best_questions(question, questions)\n",
    "    return best_question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def VLMQueryRewritingCog(query, image):\n",
    "\n",
    "    # 1. Call VLM to get caption of the image\n",
    "    caption = ...\n",
    "\n",
    "    # 2. Re-write the Query\n",
    "    new_query = reWriteQuery(caption, query)\n",
    "\n",
    "    # 3. Ensure that the new query is gonna be used in the future instead\n",
    "    query = new_query\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cognify",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
